{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mohammad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from wordcloud import WordCloud\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amp',\n",
       " 'http',\n",
       " 'rt',\n",
       " 'RT',\n",
       " 'https',\n",
       " 'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " \"can't\",\n",
       " 'cannot',\n",
       " 'could',\n",
       " \"couldn't\",\n",
       " 'did',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " \"he's\",\n",
       " 'her',\n",
       " 'here',\n",
       " \"here's\",\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " \"how's\",\n",
       " 'i',\n",
       " \"i'd\",\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " \"i've\",\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"let's\",\n",
       " 'me',\n",
       " 'more',\n",
       " 'most',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'ought',\n",
       " 'our',\n",
       " 'ours\\tourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 'same',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that's\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " \"there's\",\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 'very',\n",
       " 'was',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " \"we've\",\n",
       " 'were',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " \"what's\",\n",
       " 'when',\n",
       " \"when's\",\n",
       " 'where',\n",
       " \"where's\",\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " \"who's\",\n",
       " 'whom',\n",
       " 'why',\n",
       " \"why's\",\n",
       " 'with',\n",
       " \"won't\",\n",
       " 'would',\n",
       " \"wouldn't\",\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'a',\n",
       " \"a's\",\n",
       " 'able',\n",
       " 'about',\n",
       " 'above',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'across',\n",
       " 'actually',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " \"ain't\",\n",
       " 'all',\n",
       " 'allow',\n",
       " 'allows',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anyhow',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'apart',\n",
       " 'appear',\n",
       " 'appreciate',\n",
       " 'appropriate',\n",
       " 'are',\n",
       " \"aren't\",\n",
       " 'around',\n",
       " 'as',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asking',\n",
       " 'associated',\n",
       " 'at',\n",
       " 'available',\n",
       " 'away',\n",
       " 'awfully',\n",
       " 'b',\n",
       " 'be',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beforehand',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'believe',\n",
       " 'below',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'better',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'both',\n",
       " 'brief',\n",
       " 'but',\n",
       " 'by',\n",
       " 'c',\n",
       " \"c'mon\",\n",
       " \"c's\",\n",
       " 'came',\n",
       " 'can',\n",
       " \"can't\",\n",
       " 'cannot',\n",
       " 'cant',\n",
       " 'cause',\n",
       " 'causes',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'changes',\n",
       " 'clearly',\n",
       " 'co',\n",
       " 'com',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'concerning',\n",
       " 'consequently',\n",
       " 'consider',\n",
       " 'considering',\n",
       " 'contain',\n",
       " 'containing',\n",
       " 'contains',\n",
       " 'corresponding',\n",
       " 'could',\n",
       " \"couldn't\",\n",
       " 'course',\n",
       " 'currently',\n",
       " 'd',\n",
       " 'definitely',\n",
       " 'described',\n",
       " 'despite',\n",
       " 'did',\n",
       " \"didn't\",\n",
       " 'different',\n",
       " 'do',\n",
       " 'does',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " \"don't\",\n",
       " 'done',\n",
       " 'down',\n",
       " 'downwards',\n",
       " 'during',\n",
       " 'e',\n",
       " 'each',\n",
       " 'edu',\n",
       " 'eg',\n",
       " 'eight',\n",
       " 'either',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'enough',\n",
       " 'entirely',\n",
       " 'especially',\n",
       " 'et',\n",
       " 'etc',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everybody',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'ex',\n",
       " 'exactly',\n",
       " 'example',\n",
       " 'except',\n",
       " 'f',\n",
       " 'far',\n",
       " 'few',\n",
       " 'fifth',\n",
       " 'first',\n",
       " 'five',\n",
       " 'followed',\n",
       " 'following',\n",
       " 'follows',\n",
       " 'for',\n",
       " 'former',\n",
       " 'formerly',\n",
       " 'forth',\n",
       " 'four',\n",
       " 'from',\n",
       " 'further',\n",
       " 'furthermore',\n",
       " 'g',\n",
       " 'get',\n",
       " 'gets',\n",
       " 'getting',\n",
       " 'given',\n",
       " 'gives',\n",
       " 'go',\n",
       " 'goes',\n",
       " 'going',\n",
       " 'gone',\n",
       " 'got',\n",
       " 'gotten',\n",
       " 'greetings',\n",
       " 'h',\n",
       " 'had',\n",
       " \"hadn't\",\n",
       " 'happens',\n",
       " 'hardly',\n",
       " 'has',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he's\",\n",
       " 'hello',\n",
       " 'help',\n",
       " 'hence',\n",
       " 'her',\n",
       " 'here',\n",
       " \"here's\",\n",
       " 'hereafter',\n",
       " 'hereby',\n",
       " 'herein',\n",
       " 'hereupon',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'hi',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'hither',\n",
       " 'hopefully',\n",
       " 'how',\n",
       " 'howbeit',\n",
       " 'however',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " \"i've\",\n",
       " 'ie',\n",
       " 'if',\n",
       " 'ignored',\n",
       " 'immediate',\n",
       " 'in',\n",
       " 'inasmuch',\n",
       " 'inc',\n",
       " 'indeed',\n",
       " 'indicate',\n",
       " 'indicated',\n",
       " 'indicates',\n",
       " 'inner',\n",
       " 'insofar',\n",
       " 'instead',\n",
       " 'into',\n",
       " 'inward',\n",
       " 'is',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'j',\n",
       " 'just',\n",
       " 'k',\n",
       " 'keep',\n",
       " 'keeps',\n",
       " 'kept',\n",
       " 'know',\n",
       " 'knows',\n",
       " 'known',\n",
       " 'l',\n",
       " 'last',\n",
       " 'lately',\n",
       " 'later',\n",
       " 'latter',\n",
       " 'latterly',\n",
       " 'least',\n",
       " 'less',\n",
       " 'lest',\n",
       " 'let',\n",
       " \"let's\",\n",
       " 'like',\n",
       " 'liked',\n",
       " 'likely',\n",
       " 'little',\n",
       " 'look',\n",
       " 'looking',\n",
       " 'looks',\n",
       " 'ltd',\n",
       " 'm',\n",
       " 'mainly',\n",
       " 'many',\n",
       " 'may',\n",
       " 'maybe',\n",
       " 'me',\n",
       " 'mean',\n",
       " 'meanwhile',\n",
       " 'merely',\n",
       " 'might',\n",
       " 'more',\n",
       " 'moreover',\n",
       " 'most',\n",
       " 'mostly',\n",
       " 'much',\n",
       " 'must',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'n',\n",
       " 'name',\n",
       " 'namely',\n",
       " 'nd',\n",
       " 'near',\n",
       " 'nearly',\n",
       " 'necessary',\n",
       " 'need',\n",
       " 'needs',\n",
       " 'neither',\n",
       " 'never',\n",
       " 'nevertheless',\n",
       " 'new',\n",
       " 'next',\n",
       " 'nine',\n",
       " 'no',\n",
       " 'nobody',\n",
       " 'non',\n",
       " 'none',\n",
       " 'noone',\n",
       " 'nor',\n",
       " 'normally',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'novel',\n",
       " 'now',\n",
       " 'nowhere',\n",
       " 'o',\n",
       " 'obviously',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'oh',\n",
       " 'ok',\n",
       " 'okay',\n",
       " 'old',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'ones',\n",
       " 'only',\n",
       " 'onto',\n",
       " 'or',\n",
       " 'other',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'ought',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'outside',\n",
       " 'over',\n",
       " 'overall',\n",
       " 'own',\n",
       " 'p',\n",
       " 'particular',\n",
       " 'particularly',\n",
       " 'per',\n",
       " 'perhaps',\n",
       " 'placed',\n",
       " 'please',\n",
       " 'plus',\n",
       " 'possible',\n",
       " 'presumably',\n",
       " 'probably',\n",
       " 'provides',\n",
       " 'q',\n",
       " 'que',\n",
       " 'quite',\n",
       " 'qv',\n",
       " 'r',\n",
       " 'rather',\n",
       " 'rd',\n",
       " 're',\n",
       " 'really',\n",
       " 'reasonably',\n",
       " 'regarding',\n",
       " 'regardless',\n",
       " 'regards',\n",
       " 'relatively',\n",
       " 'respectively',\n",
       " 'right',\n",
       " 's',\n",
       " 'said',\n",
       " 'same',\n",
       " 'saw',\n",
       " 'say',\n",
       " 'saying',\n",
       " 'says',\n",
       " 'second',\n",
       " 'secondly',\n",
       " 'see',\n",
       " 'seeing',\n",
       " 'seem',\n",
       " 'seemed',\n",
       " 'seeming',\n",
       " 'seems',\n",
       " 'seen',\n",
       " 'self',\n",
       " 'selves',\n",
       " 'sensible',\n",
       " 'sent',\n",
       " 'serious',\n",
       " 'seriously',\n",
       " 'seven',\n",
       " 'several',\n",
       " 'shall',\n",
       " 'she',\n",
       " 'should',\n",
       " \"shouldn't\",\n",
       " 'since',\n",
       " 'six',\n",
       " 'so',\n",
       " 'some',\n",
       " 'somebody',\n",
       " 'somehow',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'sometime',\n",
       " 'sometimes',\n",
       " 'somewhat',\n",
       " 'somewhere',\n",
       " 'soon',\n",
       " 'sorry',\n",
       " 'specified',\n",
       " 'specify',\n",
       " 'specifying',\n",
       " 'still',\n",
       " 'sub',\n",
       " 'such',\n",
       " 'sup',\n",
       " 'sure',\n",
       " 't',\n",
       " \"t's\",\n",
       " 'take',\n",
       " 'taken',\n",
       " 'tell',\n",
       " 'tends',\n",
       " 'th',\n",
       " 'than',\n",
       " 'thank',\n",
       " 'thanks',\n",
       " 'thanx',\n",
       " 'that',\n",
       " \"that's\",\n",
       " 'thats',\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'thence',\n",
       " 'there',\n",
       " \"there's\",\n",
       " 'thereafter',\n",
       " 'thereby',\n",
       " 'therefore',\n",
       " 'therein',\n",
       " 'theres',\n",
       " 'thereupon',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'think',\n",
       " 'third',\n",
       " 'this',\n",
       " 'thorough',\n",
       " 'thoroughly',\n",
       " 'those',\n",
       " 'though',\n",
       " 'three',\n",
       " 'through',\n",
       " 'throughout',\n",
       " 'thru',\n",
       " 'thus',\n",
       " 'to',\n",
       " 'together',\n",
       " 'too',\n",
       " 'took',\n",
       " 'toward',\n",
       " 'towards',\n",
       " 'tried',\n",
       " 'tries',\n",
       " 'truly',\n",
       " 'try',\n",
       " 'trying',\n",
       " 'twice',\n",
       " 'two',\n",
       " 'u',\n",
       " 'un',\n",
       " 'under',\n",
       " 'unfortunately',\n",
       " 'unless',\n",
       " 'unlikely',\n",
       " 'until',\n",
       " 'unto',\n",
       " 'up',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'use',\n",
       " 'used',\n",
       " 'useful',\n",
       " 'uses',\n",
       " 'using',\n",
       " 'usually',\n",
       " 'uucp',\n",
       " 'v',\n",
       " 'value',\n",
       " 'various',\n",
       " 'very',\n",
       " 'via',\n",
       " 'viz',\n",
       " 'vs',\n",
       " 'w',\n",
       " 'want',\n",
       " 'wants',\n",
       " 'was',\n",
       " \"wasn't\",\n",
       " 'way',\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " \"we've\",\n",
       " 'welcome',\n",
       " 'well',\n",
       " 'went',\n",
       " 'were',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " \"what's\",\n",
       " 'whatever',\n",
       " 'when',\n",
       " 'whence',\n",
       " 'whenever',\n",
       " 'where',\n",
       " \"where's\",\n",
       " 'whereafter',\n",
       " 'whereas',\n",
       " 'whereby',\n",
       " 'wherein',\n",
       " 'whereupon',\n",
       " 'wherever',\n",
       " 'whether',\n",
       " 'which',\n",
       " 'while',\n",
       " 'whither',\n",
       " 'who',\n",
       " \"who's\",\n",
       " 'whoever',\n",
       " 'whole',\n",
       " 'whom',\n",
       " 'whose',\n",
       " 'why',\n",
       " 'will',\n",
       " 'willing',\n",
       " 'wish',\n",
       " 'with',\n",
       " 'within',\n",
       " 'without',\n",
       " \"won't\",\n",
       " 'wonder',\n",
       " 'would',\n",
       " 'would',\n",
       " \"wouldn't\",\n",
       " 'x',\n",
       " 'y',\n",
       " 'yes',\n",
       " 'yet',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'z',\n",
       " 'zero',\n",
       " 'one',\n",
       " 'every',\n",
       " 'least',\n",
       " 'less',\n",
       " 'many',\n",
       " 'now',\n",
       " 'ever',\n",
       " 'never',\n",
       " 'say',\n",
       " 'says',\n",
       " 'said',\n",
       " 'ï»؟a',\n",
       " 'able',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abst',\n",
       " 'accordance',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'across',\n",
       " 'act',\n",
       " 'actually',\n",
       " 'added',\n",
       " 'adj',\n",
       " 'adopted',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affects',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ah',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'an',\n",
       " 'and',\n",
       " 'announce',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anyhow',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'apparently',\n",
       " 'approximately',\n",
       " 'are',\n",
       " 'aren',\n",
       " 'arent',\n",
       " 'arise',\n",
       " 'around',\n",
       " 'as',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asking',\n",
       " 'at',\n",
       " 'auth',\n",
       " 'available',\n",
       " 'away',\n",
       " 'awfully',\n",
       " 'b',\n",
       " 'back',\n",
       " 'be',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beforehand',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'beginnings',\n",
       " 'begins',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'believe',\n",
       " 'below',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'biol',\n",
       " 'both',\n",
       " 'brief',\n",
       " 'briefly',\n",
       " 'but',\n",
       " 'by',\n",
       " 'c',\n",
       " 'ca',\n",
       " 'came',\n",
       " 'can',\n",
       " 'cannot',\n",
       " \"can't\",\n",
       " 'cause',\n",
       " 'causes',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'co',\n",
       " 'com',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'contain',\n",
       " 'containing',\n",
       " 'contains',\n",
       " 'could',\n",
       " 'couldnt',\n",
       " 'd',\n",
       " 'date',\n",
       " 'did',\n",
       " \"didn't\",\n",
       " 'different',\n",
       " 'do',\n",
       " 'does',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'done',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'downwards',\n",
       " 'due',\n",
       " 'during',\n",
       " 'e',\n",
       " 'each',\n",
       " 'ed',\n",
       " 'edu',\n",
       " 'effect',\n",
       " 'eg',\n",
       " 'eight',\n",
       " 'eighty',\n",
       " 'either',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'end',\n",
       " 'ending',\n",
       " 'enough',\n",
       " 'especially',\n",
       " 'et',\n",
       " 'et-al',\n",
       " 'etc',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everybody',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'ex',\n",
       " 'except',\n",
       " 'f',\n",
       " 'far',\n",
       " 'few',\n",
       " 'ff',\n",
       " 'fifth',\n",
       " 'first',\n",
       " 'five',\n",
       " 'fix',\n",
       " 'followed',\n",
       " 'following',\n",
       " 'follows',\n",
       " 'for',\n",
       " 'former',\n",
       " 'formerly',\n",
       " 'forth',\n",
       " 'found',\n",
       " 'four',\n",
       " 'from',\n",
       " 'further',\n",
       " 'furthermore',\n",
       " 'g',\n",
       " 'gave',\n",
       " 'get',\n",
       " 'gets',\n",
       " 'getting',\n",
       " 'give',\n",
       " 'given',\n",
       " 'gives',\n",
       " 'giving',\n",
       " 'go',\n",
       " 'goes',\n",
       " 'gone',\n",
       " 'got',\n",
       " 'gotten',\n",
       " 'h',\n",
       " 'had',\n",
       " 'happens',\n",
       " 'hardly',\n",
       " 'has',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'hed',\n",
       " 'hence',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hereafter',\n",
       " 'hereby',\n",
       " 'herein',\n",
       " 'heres',\n",
       " 'hereupon',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'hes',\n",
       " 'hi',\n",
       " 'hid',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'hither',\n",
       " 'home',\n",
       " 'how',\n",
       " 'howbeit',\n",
       " 'however',\n",
       " 'hundred',\n",
       " 'i',\n",
       " 'id',\n",
       " 'ie',\n",
       " 'if',\n",
       " \"i'll\",\n",
       " 'im',\n",
       " 'immediate',\n",
       " 'immediately',\n",
       " 'importance',\n",
       " 'important',\n",
       " 'in',\n",
       " 'inc',\n",
       " 'indeed',\n",
       " 'index',\n",
       " 'information',\n",
       " 'instead',\n",
       " 'into',\n",
       " 'invention',\n",
       " 'inward',\n",
       " 'is',\n",
       " \"isn't\",\n",
       " ...]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOPWORDS=[]\n",
    "with open(\"F:\\\\Courses in ISU\\\\Box Sync\\\\Incubator\\\\wc\\\\wc\\\\stop\", 'r') as stop:\n",
    "        for line in stop:\n",
    "            STOPWORDS.append(line.strip())\n",
    "STOPWORDS    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>label3</th>\n",
       "      <th>category</th>\n",
       "      <th>category_id</th>\n",
       "      <th>acc_name</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100576524910076000</td>\n",
       "      <td>In honor of Mark O. Hatfield, for which the ne...</td>\n",
       "      <td>politics</td>\n",
       "      <td>news</td>\n",
       "      <td>politics</td>\n",
       "      <td>health</td>\n",
       "      <td>11</td>\n",
       "      <td>NIHClinicalCntr</td>\n",
       "      <td>20186316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103159453934821000</td>\n",
       "      <td>Now is the time for agencies to get smarter ab...</td>\n",
       "      <td>no topic</td>\n",
       "      <td>other</td>\n",
       "      <td>politics</td>\n",
       "      <td>electronics</td>\n",
       "      <td>7</td>\n",
       "      <td>IBM</td>\n",
       "      <td>18994444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103753827928375000</td>\n",
       "      <td>60 second impressions http://t.co/MPMb6pF #sum...</td>\n",
       "      <td>no topic</td>\n",
       "      <td>education</td>\n",
       "      <td>health</td>\n",
       "      <td>education</td>\n",
       "      <td>6</td>\n",
       "      <td>Cambridge_Uni</td>\n",
       "      <td>33474655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103830795642352000</td>\n",
       "      <td>CC Research featured on WebMD: Fat Around Hear...</td>\n",
       "      <td>health</td>\n",
       "      <td>health</td>\n",
       "      <td>gaming</td>\n",
       "      <td>health</td>\n",
       "      <td>11</td>\n",
       "      <td>NIHClinicalCntr</td>\n",
       "      <td>20186316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104560799762231000</td>\n",
       "      <td>CCNews - Teen Retreat reminds patients of iden...</td>\n",
       "      <td>auto</td>\n",
       "      <td>news</td>\n",
       "      <td>news</td>\n",
       "      <td>health</td>\n",
       "      <td>11</td>\n",
       "      <td>NIHClinicalCntr</td>\n",
       "      <td>20186316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                               text  \\\n",
       "0  100576524910076000  In honor of Mark O. Hatfield, for which the ne...   \n",
       "1  103159453934821000  Now is the time for agencies to get smarter ab...   \n",
       "2  103753827928375000  60 second impressions http://t.co/MPMb6pF #sum...   \n",
       "3  103830795642352000  CC Research featured on WebMD: Fat Around Hear...   \n",
       "4  104560799762231000  CCNews - Teen Retreat reminds patients of iden...   \n",
       "\n",
       "     label1     label2    label3     category  category_id         acc_name  \\\n",
       "0  politics       news  politics       health           11  NIHClinicalCntr   \n",
       "1  no topic      other  politics  electronics            7              IBM   \n",
       "2  no topic  education    health    education            6    Cambridge_Uni   \n",
       "3    health     health    gaming       health           11  NIHClinicalCntr   \n",
       "4      auto       news      news       health           11  NIHClinicalCntr   \n",
       "\n",
       "        uid  \n",
       "0  20186316  \n",
       "1  18994444  \n",
       "2  33474655  \n",
       "3  20186316  \n",
       "4  20186316  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_label_df = pd.read_csv('F:\\\\Courses in ISU\\\\Box Sync\\\\Incubator\\\\tweets\\\\labeledtweets\\\\three_label_df1.csv')\n",
    "three_label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "three_label_filtered_df=three_label_df[ ((three_label_df['label1'] == three_label_df['label2'])\n",
    "                    & (three_label_df['label1'] == three_label_df['label3']) & (three_label_df['label1'] == three_label_df['category'])) \n",
    "                   | ((three_label_df['label1'] == three_label_df['label2'])\n",
    "                    & (three_label_df['label1'] == three_label_df['category']))\n",
    "                    \n",
    "                   | ((three_label_df['label2'] == three_label_df['label3'])\n",
    "                    & (three_label_df['label2'] == three_label_df['category']))\n",
    "                    \n",
    "                     | ((three_label_df['label1'] == three_label_df['label3'])\n",
    "                    & (three_label_df['label3'] == three_label_df['category']))\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>label3</th>\n",
       "      <th>category</th>\n",
       "      <th>category_id</th>\n",
       "      <th>acc_name</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103830795642352000</td>\n",
       "      <td>CC Research featured on WebMD: Fat Around Hear...</td>\n",
       "      <td>health</td>\n",
       "      <td>health</td>\n",
       "      <td>gaming</td>\n",
       "      <td>health</td>\n",
       "      <td>11</td>\n",
       "      <td>NIHClinicalCntr</td>\n",
       "      <td>20186316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10589428772</td>\n",
       "      <td>RT @rzrachelzoe http://twitpic.com/190077 in t...</td>\n",
       "      <td>news</td>\n",
       "      <td>fashion</td>\n",
       "      <td>fashion</td>\n",
       "      <td>fashion</td>\n",
       "      <td>8</td>\n",
       "      <td>Versace</td>\n",
       "      <td>72568426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>109383508702659000</td>\n",
       "      <td>If you agree career politicians got us into th...</td>\n",
       "      <td>politics</td>\n",
       "      <td>politics</td>\n",
       "      <td>politics</td>\n",
       "      <td>politics</td>\n",
       "      <td>13</td>\n",
       "      <td>MittRomney</td>\n",
       "      <td>50055701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>110399896934294000</td>\n",
       "      <td>Whether you are at the beach, at the lake, or ...</td>\n",
       "      <td>no topic</td>\n",
       "      <td>fashion</td>\n",
       "      <td>fashion</td>\n",
       "      <td>fashion</td>\n",
       "      <td>8</td>\n",
       "      <td>TommyHilfiger</td>\n",
       "      <td>30180137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>111162463508103000</td>\n",
       "      <td>News release: Johnson &amp; Johnson To Participate...</td>\n",
       "      <td>health</td>\n",
       "      <td>health</td>\n",
       "      <td>basketball</td>\n",
       "      <td>health</td>\n",
       "      <td>11</td>\n",
       "      <td>JNJNews</td>\n",
       "      <td>20457806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                               text  \\\n",
       "3   103830795642352000  CC Research featured on WebMD: Fat Around Hear...   \n",
       "7          10589428772  RT @rzrachelzoe http://twitpic.com/190077 in t...   \n",
       "14  109383508702659000  If you agree career politicians got us into th...   \n",
       "15  110399896934294000  Whether you are at the beach, at the lake, or ...   \n",
       "16  111162463508103000  News release: Johnson & Johnson To Participate...   \n",
       "\n",
       "      label1    label2      label3  category  category_id         acc_name  \\\n",
       "3     health    health      gaming    health           11  NIHClinicalCntr   \n",
       "7       news   fashion     fashion   fashion            8          Versace   \n",
       "14  politics  politics    politics  politics           13       MittRomney   \n",
       "15  no topic   fashion     fashion   fashion            8    TommyHilfiger   \n",
       "16    health    health  basketball    health           11          JNJNews   \n",
       "\n",
       "         uid  \n",
       "3   20186316  \n",
       "7   72568426  \n",
       "14  50055701  \n",
       "15  30180137  \n",
       "16  20457806  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_label_filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohammad\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "def claening_process(row):\n",
    "    new_row = re.sub('[^a-zA-Z]', ' ', row['text'])\n",
    "    new_row = new_row.lower()\n",
    "    new_row = new_row.split()\n",
    "    ps = PorterStemmer()\n",
    "    new_row = [ps.stem(word) for word in new_row if not word in (set(stopwords.words('english')) and STOPWORDS)]\n",
    "    new_row = ' '.join(new_row)\n",
    "    return new_row\n",
    "three_label_filtered_df['text_new']=three_label_filtered_df.apply(claening_process, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC Research featured on WebMD: Fat Around Hear...</td>\n",
       "      <td>cc featur webmd fat heart link clog arteri gl ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RT @rzrachelzoe http://twitpic.com/190077 in t...</td>\n",
       "      <td>rzrachelzo twitpic digit studio photoshoot bra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>If you agree career politicians got us into th...</td>\n",
       "      <td>agre career politician mess don click rigxrto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Whether you are at the beach, at the lake, or ...</td>\n",
       "      <td>beach lake wear today sundaystyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>News release: Johnson &amp; Johnson To Participate...</td>\n",
       "      <td>news releas johnson johnson particip morgan st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "3   CC Research featured on WebMD: Fat Around Hear...   \n",
       "7   RT @rzrachelzoe http://twitpic.com/190077 in t...   \n",
       "14  If you agree career politicians got us into th...   \n",
       "15  Whether you are at the beach, at the lake, or ...   \n",
       "16  News release: Johnson & Johnson To Participate...   \n",
       "\n",
       "                                             text_new  \n",
       "3   cc featur webmd fat heart link clog arteri gl ...  \n",
       "7   rzrachelzo twitpic digit studio photoshoot bra...  \n",
       "14      agre career politician mess don click rigxrto  \n",
       "15                   beach lake wear today sundaystyl  \n",
       "16  news releas johnson johnson particip morgan st...  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_label_filtered_df[['text', 'text_new']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>label3</th>\n",
       "      <th>category</th>\n",
       "      <th>category_id</th>\n",
       "      <th>acc_name</th>\n",
       "      <th>uid</th>\n",
       "      <th>text_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103830795642352000</td>\n",
       "      <td>CC Research featured on WebMD: Fat Around Hear...</td>\n",
       "      <td>health</td>\n",
       "      <td>health</td>\n",
       "      <td>gaming</td>\n",
       "      <td>health</td>\n",
       "      <td>11</td>\n",
       "      <td>NIHClinicalCntr</td>\n",
       "      <td>20186316</td>\n",
       "      <td>cc featur webmd fat heart link clog arteri gl ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10589428772</td>\n",
       "      <td>RT @rzrachelzoe http://twitpic.com/190077 in t...</td>\n",
       "      <td>news</td>\n",
       "      <td>fashion</td>\n",
       "      <td>fashion</td>\n",
       "      <td>fashion</td>\n",
       "      <td>8</td>\n",
       "      <td>Versace</td>\n",
       "      <td>72568426</td>\n",
       "      <td>rzrachelzo twitpic digit studio photoshoot bra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>109383508702659000</td>\n",
       "      <td>If you agree career politicians got us into th...</td>\n",
       "      <td>politics</td>\n",
       "      <td>politics</td>\n",
       "      <td>politics</td>\n",
       "      <td>politics</td>\n",
       "      <td>13</td>\n",
       "      <td>MittRomney</td>\n",
       "      <td>50055701</td>\n",
       "      <td>agre career politician mess don click rigxrto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>110399896934294000</td>\n",
       "      <td>Whether you are at the beach, at the lake, or ...</td>\n",
       "      <td>no topic</td>\n",
       "      <td>fashion</td>\n",
       "      <td>fashion</td>\n",
       "      <td>fashion</td>\n",
       "      <td>8</td>\n",
       "      <td>TommyHilfiger</td>\n",
       "      <td>30180137</td>\n",
       "      <td>beach lake wear today sundaystyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>111162463508103000</td>\n",
       "      <td>News release: Johnson &amp; Johnson To Participate...</td>\n",
       "      <td>health</td>\n",
       "      <td>health</td>\n",
       "      <td>basketball</td>\n",
       "      <td>health</td>\n",
       "      <td>11</td>\n",
       "      <td>JNJNews</td>\n",
       "      <td>20457806</td>\n",
       "      <td>news releas johnson johnson particip morgan st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>111404118828003000</td>\n",
       "      <td>@MoneySavingExp We think Oxford has the highes...</td>\n",
       "      <td>news</td>\n",
       "      <td>education</td>\n",
       "      <td>education</td>\n",
       "      <td>education</td>\n",
       "      <td>6</td>\n",
       "      <td>UniofOxford</td>\n",
       "      <td>48289662</td>\n",
       "      <td>moneysavingexp oxford highest student support ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>111808259706454000</td>\n",
       "      <td>MT @TreasurerLoftis I enjoyed tonight's @MittR...</td>\n",
       "      <td>politics</td>\n",
       "      <td>politics</td>\n",
       "      <td>politics</td>\n",
       "      <td>politics</td>\n",
       "      <td>13</td>\n",
       "      <td>MittRomney</td>\n",
       "      <td>50055701</td>\n",
       "      <td>mt treasurerlofti enjoy tonight mittromney deb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>111970647613260000</td>\n",
       "      <td>GIANNI WOULD BE PROUD @VERSACE #FNO</td>\n",
       "      <td>news</td>\n",
       "      <td>fashion</td>\n",
       "      <td>fashion</td>\n",
       "      <td>fashion</td>\n",
       "      <td>8</td>\n",
       "      <td>Versace</td>\n",
       "      <td>72568426</td>\n",
       "      <td>gianni versac fno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>111976817883234000</td>\n",
       "      <td>The Fiat 500 by Gucci is debuting at Gucci's 5...</td>\n",
       "      <td>fashion</td>\n",
       "      <td>auto</td>\n",
       "      <td>fashion</td>\n",
       "      <td>fashion</td>\n",
       "      <td>8</td>\n",
       "      <td>gucci</td>\n",
       "      <td>16913418</td>\n",
       "      <td>fiat gucci debut gucci avenu flagship store ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>112201619046810000</td>\n",
       "      <td>Did you miss our Fashion's Night Out festiviti...</td>\n",
       "      <td>fashion</td>\n",
       "      <td>fashion</td>\n",
       "      <td>fashion</td>\n",
       "      <td>fashion</td>\n",
       "      <td>8</td>\n",
       "      <td>TommyHilfiger</td>\n",
       "      <td>30180137</td>\n",
       "      <td>fashion night festiv york check video recap ky...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                               text  \\\n",
       "3   103830795642352000  CC Research featured on WebMD: Fat Around Hear...   \n",
       "7          10589428772  RT @rzrachelzoe http://twitpic.com/190077 in t...   \n",
       "14  109383508702659000  If you agree career politicians got us into th...   \n",
       "15  110399896934294000  Whether you are at the beach, at the lake, or ...   \n",
       "16  111162463508103000  News release: Johnson & Johnson To Participate...   \n",
       "17  111404118828003000  @MoneySavingExp We think Oxford has the highes...   \n",
       "20  111808259706454000  MT @TreasurerLoftis I enjoyed tonight's @MittR...   \n",
       "22  111970647613260000                GIANNI WOULD BE PROUD @VERSACE #FNO   \n",
       "23  111976817883234000  The Fiat 500 by Gucci is debuting at Gucci's 5...   \n",
       "25  112201619046810000  Did you miss our Fashion's Night Out festiviti...   \n",
       "\n",
       "      label1     label2      label3   category  category_id         acc_name  \\\n",
       "3     health     health      gaming     health           11  NIHClinicalCntr   \n",
       "7       news    fashion     fashion    fashion            8          Versace   \n",
       "14  politics   politics    politics   politics           13       MittRomney   \n",
       "15  no topic    fashion     fashion    fashion            8    TommyHilfiger   \n",
       "16    health     health  basketball     health           11          JNJNews   \n",
       "17      news  education   education  education            6      UniofOxford   \n",
       "20  politics   politics    politics   politics           13       MittRomney   \n",
       "22      news    fashion     fashion    fashion            8          Versace   \n",
       "23   fashion       auto     fashion    fashion            8            gucci   \n",
       "25   fashion    fashion     fashion    fashion            8    TommyHilfiger   \n",
       "\n",
       "         uid                                           text_new  \n",
       "3   20186316  cc featur webmd fat heart link clog arteri gl ...  \n",
       "7   72568426  rzrachelzo twitpic digit studio photoshoot bra...  \n",
       "14  50055701      agre career politician mess don click rigxrto  \n",
       "15  30180137                   beach lake wear today sundaystyl  \n",
       "16  20457806  news releas johnson johnson particip morgan st...  \n",
       "17  48289662  moneysavingexp oxford highest student support ...  \n",
       "20  50055701  mt treasurerlofti enjoy tonight mittromney deb...  \n",
       "22  72568426                                  gianni versac fno  \n",
       "23  16913418  fiat gucci debut gucci avenu flagship store ti...  \n",
       "25  30180137  fashion night festiv york check video recap ky...  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=three_label_filtered_df.iloc[0:10]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=three_label_filtered_df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cc featur webmd fat heart link clog arteri gl vcvz',\n",
       "       'rzrachelzo twitpic digit studio photoshoot brad glamour uk shoe insan versac xorz',\n",
       "       'agre career politician mess don click rigxrto', ...,\n",
       "       'versac collect redesign volum outerwear emphas proport shape',\n",
       "       'gucci live today facebook gucci iwebcast liveshow gucci app',\n",
       "       'nvidia foundat support work breakthrough silicon valley group bit ly hbrd'], dtype=object)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc = WordCloud(background_color=None,\n",
    "               mode=\"RGBA\",\n",
    "               width=1800,\n",
    "               height=1400,\n",
    "               mask=twitter_mask,\n",
    "               prefer_horizontal=1)\n",
    "a=(three_label_filtered_df[three_label_filtered_df['category'] == 'health'])['text_new'].values\n",
    "text = \" \".join(a)\n",
    "wc.generate(text)\n",
    "wc.to_file(\"wc_health.png\")\n",
    "\n",
    "a=(df[df['category'] == 'airline'])['text_new'].values\n",
    "text = \" \".join(a)\n",
    "wc.generate(text)\n",
    "wc.to_file(\"wc_airline.png\")\n",
    "\n",
    "\n",
    "a=(df[df['category'] == 'soccer'])['text_new'].values\n",
    "text = \" \".join(a)\n",
    "wc.generate(text)\n",
    "wc.to_file(\"wc_soccer.png\")\n",
    "\n",
    "a=(df[df['category'] == 'fashion'])['text_new'].values\n",
    "text = \" \".join(a)\n",
    "wc.generate(text)\n",
    "wc.to_file(\"wc_fashion.png\")\n",
    "\n",
    "corpus = three_label_filtered_df['text_new'].values\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vec = CountVectorizer()\n",
    "X = count_vec.fit_transform(corpus).toarray()\n",
    "y = three_label_filtered_df.loc[:, 'category'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[26,  1,  2,  1,  0,  0,  0,  0,  1,  0,  1,  0,  1,  2,  0,  0],\n",
       "       [ 1, 15,  3,  3,  2,  2,  1,  0,  0,  0,  0,  0,  1,  1,  0,  1],\n",
       "       [ 0,  2, 49,  2,  1,  0,  1,  1,  0,  0,  0,  2,  2,  0,  3,  0],\n",
       "       [ 0,  0,  2, 69,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  2,  2],\n",
       "       [ 0,  1,  2,  1, 21,  1,  1,  1,  2,  1,  0,  0,  1,  1,  0,  2],\n",
       "       [ 0,  1,  0,  0,  0,  9,  3,  0,  0,  0,  1,  0,  0,  0,  0,  0],\n",
       "       [ 0,  1,  1,  0,  1,  1, 15,  0,  1,  0,  0,  2,  3,  3,  1,  0],\n",
       "       [ 1,  0,  2,  0,  1,  0,  1, 16,  1,  0,  2,  0,  0,  1,  1,  0],\n",
       "       [ 0,  1,  0,  0,  2,  0,  0,  0, 47,  0,  0,  1,  3,  0,  0,  1],\n",
       "       [ 0,  0,  1,  0,  0,  0,  0,  0,  0, 11,  0,  0,  1,  4,  2,  1],\n",
       "       [ 0,  0,  0,  3,  0,  0,  1,  0,  0,  0, 20,  0,  3,  1,  1,  0],\n",
       "       [ 1,  2,  0,  2,  1,  0,  3,  2,  1,  1,  0, 48,  5,  3,  0,  0],\n",
       "       [ 0,  0,  2,  2,  0,  0,  2,  0,  2,  0,  1,  3, 54,  2,  1,  0],\n",
       "       [ 0,  0,  1,  1,  0,  0,  1,  1,  0,  1,  0,  2, 10, 49,  1,  0],\n",
       "       [ 1,  0,  0,  4,  0,  0,  1,  0,  0,  0,  0,  0,  0,  1, 71,  0],\n",
       "       [ 0,  0,  1,  0,  0,  2,  0,  1,  0,  0,  0,  0,  0,  1,  0,  3]], dtype=int64)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
